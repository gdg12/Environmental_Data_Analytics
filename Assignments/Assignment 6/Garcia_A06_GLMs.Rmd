---
title: "Assignment 6: Generalized Linear Models"
author: "Gaby Garcia"
output: pdf_document
geometry: margin=2.54cm
editor_options: 
  chunk_output_type: inline
---

## OVERVIEW

This exercise accompanies the lessons in Environmental Data Analytics (ENV872L) on generalized linear models. 

## Directions
1. Change "Student Name" on line 3 (above) with your name.
2. Use the lesson as a guide. It contains code that can be modified to complete the assignment.
3. Work through the steps, **creating code and output** that fulfill each instruction.
4. Be sure to **answer the questions** in this assignment document.
Space for your answers is provided in this document and is indicated by the ">" character.
If you need a second paragraph be sure to start the first line with ">".
You should notice that the answer is highlighted in green by RStudio. 
6. When you have completed the assignment, **Knit** the text and code into a single PDF file.
You will need to have the correct software installed to do this (see Software Installation Guide)
Press the `Knit` button in the RStudio scripting panel.
This will save the PDF output in your Assignments folder.
8. After Knitting, please submit the completed exercise (PDF file) to the dropbox in Sakai. Please add your last name into the file name (e.g., "Salk_A06_GLMs.pdf") prior to submission.

The completed exercise is due on Tuesday, 26 February, 2019 before class begins.


#1. 
Set up your session. Upload the EPA Ecotox dataset for Neonicotinoids and the NTL-LTER raw data file for chemistry/physics. 

```{r}
setwd("~/Desktop/Environmental Data Analytics/Environmental_Data_Analytics/Data/Raw")
library(tidyverse)
library(tidyr)
library(ggplot2)
library(viridis)
library(RColorBrewer)
library(colormap)
library(lubridate)
library(stats)

Neonicotinoids<-read.csv("ECOTOX_Neonicotinoids_Mortality_raw.csv")

PeterPaul.chem.nutrients <- read.csv("NTL-LTER_Lake_ChemistryPhysics_Raw.csv")

```


#2. 
Build a ggplot theme and set it as your default theme.
```{r}
library(ggthemes)
gabytheme <- theme_bw(base_size = 14) + 
  theme(plot.title=element_text(face="bold", size="20", color="IndianRed4", hjust=0.5),
        axis.title=element_text(face="bold.italic", size=11, color="black"),
axis.text = element_text(face="bold", size=10, color = "black"), 
panel.background=element_rect(fill="gray96", color="darkblue"), 
panel.border = element_rect(color = "black", size = 2),
legend.position = "top", legend.background = element_rect(fill="white", color="black"),
            legend.key = element_rect(fill="transparent", color="NA"))

```

###Set gabytheme as my default theme
```{r}
theme_set(gabytheme)
```


# Neonicotinoids test
Research question: Were studies on various neonicotinoid chemicals conducted in different years? 

#3. 
Generate a line of code to determine how many different chemicals are listed in the Chemical.Name column.
```{r}
levels(Neonicotinoids$Chemical.Name)
```


##Shapiro.Test to Test Assumption of Normality
```{r}
shapiro.test(Neonicotinoids$Pub..Year)
```
We can reject the null hypothesis that the Publication years variable is distributed normally. (Test: Shapiro Wilks, W=0.854, p<2.2e-16)


###QQPlot shows that data is definitely not normally distributed!
```{r}
qqnorm(Neonicotinoids$Pub..Year)
qqline(Neonicotinoids$Pub..Year)
```



#4.

Are the publication years associated with each chemical well-approximated by a normal distribution? Run the appropriate test and also generate a frequency polygon to illustrate the distribution of counts for each year, divided by chemical name. Bonus points if you can generate the results of your test from a pipe function. No need to make this graph pretty.
\pagebreak


```{r, warning=FALSE, message=FALSE, fig.width=10}
library(scales)

PubYearPlot <-
  ggplot(Neonicotinoids) +
  geom_freqpoly(aes(x =Pub..Year, color = Chemical.Name)) 

print(PubYearPlot)
```



5. Is there equal variance among the publication years for each chemical? Hint: var.test is not the correct function.

###Use bartlett.test for non-normal distributions(var.test is for normallly distributed populations)
```{r}
bartlett.test(Neonicotinoids$Pub..Year~Neonicotinoids$Chemical.Name)

```
###Results: (Bartlett Test: K-Squared=139.59, df=8, p<2.2e-16). Based on the results of the Bartlett test, there is not equal variance among the publication years because the p-value of the test is <0.05, which means that we reject the null hypothesis that the variances are the same amongst the publication years for each chemical. 



#6. Based on your results, which test would you choose to run to answer your research question?

> ANSWER: The research question is "Were studies on various neonicotinoid chemicals conducted in different years?" We have a Continuous response variable of Publication Year, which is an integer, and we have one categorical explanatory variable with 9 levels, which is the Chemical Name variable. I would run a Kruskal-Wallis Test for this research question. The Kruskal Wallis test is the non-parametric counterpart to the one-way ANOVA. The One-way ANOVA compares the means of the samples or groups in order to make inferences about the population means; there is only one independent variable or factor. Because our dependent variable has a non-normal distribution, we should use the Kruskal-Wallis instead of a regular one-way ANOVA. 



#7.
Run this test below. 

```{r}
NeoANOVA<- kruskal.test(Neonicotinoids$Pub..Year ~ Neonicotinoids$Chemical.Name)

NeoANOVA
```


#8

Generate a boxplot representing the range of publication years for each chemical. Adjust your graph to make it pretty.

```{r}
library(dplyr)
Neonicotinoids$Pub..Year<-as.factor(Neonicotinoids$Pub..Year)
Neonicotinoids$Pub..Year<-as.Date(Neonicotinoids$Pub..Year, format="%Y")

```

```{r}
Neonicotinoids<- mutate(Neonicotinoids, year = year(Pub..Year))
Neonicotinoids$year<-as.factor(Neonicotinoids$year)
Neonicotinoids$year<-as.Date(Neonicotinoids$year, format="%Y")
Neonicotinoids<- separate(Neonicotinoids, year, c("Y", "m", "d"))

```

  
  
```{r, fig.width=11, warning=FALSE, message=FALSE}
library(scales)

NeoPlot<-ggplot(Neonicotinoids, aes(x=Chemical.Name, y=Pub..Year, fill=Chemical.Name)) + 
  geom_boxplot() +

labs(title="The Effect of Chemical Name on Range of Publication Years",
     x="Chemical Name", y="Publication Year") +
theme(legend.title = element_text(colour="IndianRed", size=23, face="bold"))+ 
 scale_fill_brewer(palette="Set3")   #use scale_fill_brewer for boxplots 
print(NeoPlot)
 
```


#9
9. How would you summarize the conclusion of your analysis? Include a sentence summarizing your findings and include the results of your test in parentheses at the end of the sentence. 

> ANSWER: Based on the results of my statistical tests and data visualization, the publication years for each of the 9 chemicals do not follow a normal distribution. There is a significant difference between the publication years across chemical types. (Kruskal-Wallis Non-Parametric Test, df=8, p<2.2e-16, Kruskal Wallis Chi Squared=134.15)



## NTL-LTER test
Research question: What is the best set of predictors for lake temperatures in July across the monitoring period at the North Temperate Lakes LTER? 

#11

11. Wrangle your NTL-LTER dataset with a pipe function so that it contains only the following criteria: 

* Only dates in July (hint: use the daynum column). No need to consider leap years.
* Only the columns: lakename, year4, daynum, depth, temperature_C
* Only complete cases (i.e., remove NAs)

```{r}
PeterPaulJulyFiltered<-filter(PeterPaul.chem.nutrients, daynum %in% c(182:212))%>%select(lakename, year4, daynum, depth, temperature_C)%>%na.omit(PeterPaul.chem.nutrients)
```


##Visualize Data Relationships
```{r, warning=FALSE, message=FALSE}
library(GGally)
ggpairs(PeterPaulJulyFiltered)
```


##Use QQNorm and QQline on Dependant Variable of Temperature
```{r}
qqnorm(PeterPaulJulyFiltered$temperature_C)
qqline(PeterPaulJulyFiltered$temperature_C)
```
###Dependent variable is not normally distributed

```{r, warning=FALSE, message=FALSE}
ggplot(PeterPaulJulyFiltered, aes(x = year4)) +
  geom_histogram(stat = "count")

ggplot(PeterPaulJulyFiltered, aes(x =daynum)) +
  geom_histogram(stat = "count")

ggplot(PeterPaulJulyFiltered, aes(x =depth)) +
  geom_histogram(stat = "count")

```


#12

Run an AIC to determine what set of explanatory variables (year4, daynum, depth) is best suited to predict temperature. 
```{r}
TempMod<-lm(data=PeterPaulJulyFiltered, temperature_C~year4+daynum+depth)

summary(TempMod)
```

##Use step function
```{r}
library(stats)
step(TempMod)
```
###Fullest model is best according to this Stepwise Algorithm function


##Check using Stepwise Model Reduction Process

###Remove year4
```{r}
TempMod2<-update(TempMod,.~.-year4)   
```

###Summary
```{r}
summary(TempMod2)
```



##Test AIC Scores
```{r}
AIC(TempMod, TempMod2)
```
###Fullest Model is best


##Run a multiple regression on the recommended set of variables. 
```{r}
TempMod<-lm(data=PeterPaulJulyFiltered, temperature_C~year4+daynum+depth)

summary(TempMod)
```

###Check Residuals of Final Model
```{r}
par(mfrow=c(2,2))
plot(TempMod)
```

#13

 What is the final linear equation to predict temperature from your multiple regression? How much of the observed variance does this model explain?

> ANSWER:  
Temperature=-6.45+0.01(year) +0.04(daynum)-1.95(depth) + E. 
The Rsquared value is 0.74, which means my final model accounts for 74% of the variance of the dependent variable, temperature. (Test: Multiple Regression, p<2.2e-16, df=9718, R=0.74).


#14

Run an interaction effects ANCOVA to predict temperature based on depth and lakename from the same wrangled dataset.

```{r}
TempANCOVAMod<-lm(temperature_C~depth*lakename, data=PeterPaulJulyFiltered)
summary(TempANCOVAMod)
```


###Summary
```{r}
summary.aov(TempANCOVAMod)
```



#15

 Is there an interaction between depth and lakename? How much variance in the temperature observations does this explain?

> ANSWER: If the p-value for the interaction effect is less than 0.05, then we would consider the interaction among the explanatory variables to be significant. According to the above ANOVA summary using summary.aov function, there is a significant interaction bectween depth and lakename because the p value<2e-16 (Linear Regression; p<2e-16, df=8, F=48.64). Therefore, the interaction between depth and lake name is significant and should be included in the model. The adjusted r-squared, the modified R-sqaured adjusted for the number of predictors in the model, is 0.79, and thus, 79% of the variance in the response variable can be explained by the predictor variables. 



#16

 Create a graph that depicts temperature by depth, with a separate color for each lake. Add a geom_smooth (method = "lm", se = FALSE) for each lake. Make your points 50 % transparent. Adjust your y axis limits to go from 0 to 35 degrees. Clean up your graph to make it pretty. 

```{r, fig.width=12, fig.height=8, warning=FALSE, message=FALSE}
TempbyDepthPlot<-ggplot(PeterPaulJulyFiltered, aes(x =depth, y =temperature_C, color=lakename)) +
  geom_point(aes(x=depth, y=temperature_C), size=0.7, shape=16, alpha=0.5) +
    geom_smooth(aes(x =depth, y =temperature_C, span=0.1, color=lakename),
                method="lm", se=FALSE, linetype=1, size=0.5) +
  labs(title="The Effect of Depth on Temperature", x="Depth of Lake (meters)",
       y="Temperature (degrees C)") + gabytheme+
  
  theme(axis.text.y=element_text(angle = 35,  hjust = 1)) +
 scale_color_brewer(palette = "Paired")
  print(TempbyDepthPlot)

```

