
---
title: "18: Data(base) Management"
author: "Environmental Data Analytics | Kateri Salk"
date: "Spring 2019"
output: pdf_document
geometry: margin=2.54cm
editor_options: 
  chunk_output_type: inline
---

## LESSON OBJECTIVES
1. Discuss data challenges in the environmental field
2. Evaluate how data management fits into the pipeline of data analysis
3. Acquire data through database searches, R packages, and webpage scraping

## CONTEMPORARY DATA CHALLENGES

Environmental fields are experiencing massive changes related to data. Many new challenges exist today, including: 

* Big data: volume, variety, frequency
* Open data
* Long-term records
* Interconnected networks
* Verifying accuracy and integrity

## DATA MANAGEMENT

Adapted from the [DataOne data management primer](https://www.dataone.org/sites/all/documents/DataONE_BP_Primer_020212.pdf) and the [University of Alabama Library guide on data management](http://www.lib.ua.edu/wiki/sura/index.php/A_Step-By-Step_Guide_to_Data_Management)

1. Choose and assemble data management toolbox
2. Create (and revisit) your data management plan
  + Volume and type of data
  + File and folder structures/formats
  + Roles and responsibilities of personnel
  + Version control
  + Access
  + Preservation
3. Collect data
4. [Quality assurance/quality control (QA/QC)](https://www.dataone.org/best-practices/ensure-basic-quality-control)
5. Describe and document data
6. Store and preserve data in a repository

## ACCESSING DATA 
### Database searches
**Various disciplines**

[re3data](https://www.re3data.org/)

[DataOne](https://search.dataone.org/data)

[Google Dataset Search](https://toolbox.google.com/datasetsearch)

[EDI Data Portal](https://portal.edirepository.org/nis/home.jsp)

[NEON](https://www.neonscience.org/data/neon-data-portal)

[LTER](https://portal.lternet.edu/nis/home.jsp)

**Water**

[CUAHSI HydroClient](http://data.cuahsi.org/)

[CUAHSI HydroShare](https://www.hydroshare.org/search/)

**Spatial Data**

[ArcGIS](http://hub.arcgis.com/)

Search one or more of these databases to find a dataset that interests you. What did you find? 

> ANSWER: 

### R Packages
* NHANES: National Health and Nutrition Examination Survey
* TidyCensus: U.S. Census data
* FedData: Geospatial data from federal sources
* dataRetrieval: USGS and EPA water quality, streamflow, and metadata
* LAGOSNE: Multiscaled geospatial and temporal data for U.S. lakes--->**will be used in Hydrologic Data Analytics next semester**

### Data scraping
Sometimes, there may be data that we can access online but are not available in downloadable formats. Data scraping is a technique that allows us to convert unstructured data (e.g., those presented in a webpage) into a structured format (e.g., a csv file). 

Methods for scraping data (from [Analytics Vidhya data scraping guide](https://www.analyticsvidhya.com/blog/2017/03/beginners-guide-on-web-scraping-in-r-using-rvest-with-hands-on-knowledge/)): 

* Manual copy-paste
* API (retrieve data from standard code; data must be in prescribed format) 
* DOM parsing

We will be scraping today using DOM parsing. First, we need to install a tool on our web browser to be able to call the web text we need. The tool is called a Selector Gadget, which for Chrome can be found [here](https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb?hl=en). 

Now that our selector gadget is in operation, we can start the data scraping process with the `rvest` package. 

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
install.packages("rvest")
library(rvest)

# Specify website to be scraped
url <- "https://en.wikipedia.org/wiki/List_of_rivers_by_length"

# Reading the HTML code from the website
webpage <- read_html(url)

```


# Grab specific components of the website
```{r}
Name<-webpage %>% html_nodes("td:nth-child(2)") %>% html_text()  ##htmlN0des points scraper towards nodes in webpage. Pipe to html_text tells it we want to generate html text
```

```{r}
Length.km<-webpage %>% html_nodes("td:nth-child(3)") %>% html_text()
```


```{r}
DrainageArea.km2<-webpage %>% html_nodes("td:nth-child(5)") %>% html_text()
```

```{r}
Discharge.m3s = webpage %>% html_nodes("td:nth-child(6)") %>% html_text()
```

```{r}
Outflow = webpage %>% html_nodes("td:nth-child(7)") %>% html_text()
```


##Look at components of "Name"
```{r}
Name
```


# Coerce into a data frame, ensure consistent lengths
```{r}
riverdata <- data_frame(Name = Name[6:188],   ###Make a data frame, grab specific lines from Name column on Wiki
                        Length.km = Length.km[2:184],   ###get 183 rows in final dataframe from Length column on Wiki
                        DrainageArea.km2 = DrainageArea.km2[2:184], 
                        Discharge.m3s = Discharge.m3s[2:184], 
                        Outflow = Outflow)
```
###This data frame has commas in numbers, and R will read them as character or factors instead of numbers. Can't have commas in R.


# Remove unnecessary text from within cells
```{r}
riverdata$Name <- str_replace(riverdata$Name, "\\[.*\\]", "") ###Looks for square brackets and removes anything inside the square brackets and the brackets themselves (such as citations from Wikipedia)
riverdata$Name <- str_replace(riverdata$Name, "\n", "")  ###Take characters consisting of \n and replacing it with nothing

```
###Now we can call up the River Names like we do normally

```{r}
riverdata$Length.km <- str_replace(riverdata$Length.km, "\\*", "")
riverdata$Length.km <- str_replace(riverdata$Length.km, "\\(.*\\)", "")
riverdata$Length.km <- str_replace(riverdata$Length.km, "\\[.*\\]", "")
```
###Removes 

```{r}
riverdata$DrainageArea.km2 <- str_replace(riverdata$DrainageArea.km2, " \\(.*\\)", "")
riverdata$DrainageArea.km2 <- str_replace(riverdata$DrainageArea.km2, "\\(.*\\)", "")
riverdata$DrainageArea.km2 <- str_replace(riverdata$DrainageArea.km2, " \\[.*\\]", "")
```

```{r}
riverdata$Discharge.m3s <- str_replace(riverdata$Discharge.m3s, " \\(.*\\)", "")
riverdata$Discharge.m3s <- str_replace(riverdata$Discharge.m3s, "\\[.*\\]", "")
```


# Turn numeric values from character to numeric
```{r}
riverdata$Length.km <- as.numeric( sub(",", "", riverdata$Length.km)) ##Tell as.numeric to have substitute-replace the comma with nothing. This also adds NAs into blank cells. 
riverdata$DrainageArea.km2 <- as.numeric( sub(",", "", riverdata$DrainageArea.km2)) ###Substitute commas with nothing
riverdata$Discharge.m3s <- as.numeric( sub(",", "", riverdata$Discharge.m3s))
```


# Plot the relationships
```{r}
ggplot(riverdata, aes(x = Length.km, y = Discharge.m3s, fill = DrainageArea.km2)) + 
geom_label(data = subset(riverdata, Name == "Yukon" | Name == "Lower Tunguska"), aes(label = Name), alpha = 0.8, nudge_x = 100, nudge_y = 0.15) +
  geom_point(shape = 21, size = 3, alpha = 0.8) + ###use this to label outliers or interesting data points
  scale_fill_viridis_c(option = "inferno", begin = 0.2, end = 0.9, direction = -1) +
  theme_classic() + 
  scale_y_log10() + ###this will give us a log scale on the Y-axis, so our data points fill the plot more evenly
  labs(x = "Length (km)", y = expression("Discharge (m"^"3"*" s"^"-1"*")"), 
       fill = expression("Drainage Area (km"^"2"*")")) +
  theme(legend.position = "top", legend.key.width = unit(1, "cm"))
```
###The Amazon River has extremely high discharge, which is why it's an outlier.




