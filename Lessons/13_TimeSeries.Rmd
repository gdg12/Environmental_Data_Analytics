
---
title: "13: Time Series Analysis"
author: "Environmental Data Analytics | Kateri Salk"
date: "Spring 2019"
output: pdf_document
geometry: margin=2.54cm
editor_options: 
  chunk_output_type: inline
---

## LESSON OBJECTIVES
1. Describe the aspects of hierarchical models, fixed effects, and random effects
2. Choose and justify appropriate statistical models when time is an explanatory variable
3. Apply repeated measures ANOVA to datasets with temporal components

## SET UP YOUR DATA ANALYSIS SESSION

```{r, message = FALSE, warning = FALSE}
setwd("~/Desktop/Environmental Data Analytics/Environmental_Data_Analytics/Data/Processed")
library(tidyverse)
#install.packages("lubridate")
library(lubridate)
#install.packages("nlme")
library(nlme)
#install.packages("lsmeans")
library(lsmeans)
#install.packages("multcompView")
library(multcompView)

PeterPaul.chem <- read.csv("NTL-LTER_Lake_ChemistryPhysics_PeterPaul_Processed.csv")

# Set date to date format
PeterPaul.chem$sampledate <- as.Date(PeterPaul.chem$sampledate, 
                                               format = "%m/%d/%y")



gabytheme <- theme_bw(base_size = 14) + 
  theme(plot.title=element_text(face="bold", size="16", color="tomato2", hjust=0.5),
        axis.title=element_text(face="bold.italic", size=11, color="black"),
axis.text = element_text(face="bold", size=10, color = "black"), 
panel.background=element_rect(fill="lightgray", color="darkblue"), 
panel.border = element_rect(color = "black", size = 2),
legend.position = "top", legend.background = element_rect(fill="white", color="black"),
            legend.key = element_rect(fill="transparent", color="NA"))
theme_set(gabytheme)

```

## HIERARCHICAL MODELS=Mixed Effects Models

**Hierarchical models,** or **mixed-effects models,** are a type of linear model in which explanatory variables are given a model whose parameters are also estimated by the data. The coefficients associated with explanatory variables thus may not be a single value but instead be sampled from a distribution, called the hyper-distribution, which is defined by the modeler. The advantage of the hierarchical model is that it builds capacity to describe multiple layers of stochasticity, which enables accounting of all aspects of uncertainty in a system. Specifically, we can separately model the process of interest and the sampling process. 

The coefficients of a hierarchical model are divided into two categories: **fixed effects** and **random effects.** A **fixed effect** is a factor whose levels are experimentally determined or whose interest lies in the effects of each level (e.g., covariates, treatments, interactions). A **random effect** is a factor whose levels are sampled from a larger population, or whose interest lies in the variation among them rather than the specific effect of each level.(We're interested in the distribution of the factor rather than its value) In choosing whether you are dealing with a fixed or a random effect, consider the following questions: 

  + Do you have a particular interest in the studied factor level?
  -use a fixed effect(ex. want to know effect of a treatment)

  + Have you included all possible levels in the study?-use a fixed effect
 - If you haven't included all possible levels (like values outside of those levels or between levels, use a random effect)
  
  + Do you have interest in the variance among levels?
  -Use a random effect
  
  + Do you have interest in generalizing to factor levels that you did not study?
  -Use a random effect
  
One common variable in hierarchical models is **time.** Time can be a complicated explanatory variable, as it can act as either a fixed or a random effect depending on the study design and research question. Due to **temporal autocorrelation,** conditions measured at a single site will be highly influenced by the conditions preceding the sampling date. Therefore, two samples taken in relatively close temporal proximity may not necessarily be independent of one another. Treating time as a random effect will account for temporal trends in observations (e.g., diel or seasonal patterns) that may not be of interest for your study.

-diel-changes happening over course of a day
-A condition on a date might depend on a condition that happened previously


Another common variable in hierarchical models is **space.** In many situations, we may want to infer conditions beyond the sites that we have sampled. By treating space as a random variable, we may be able to extrapolate conditions of the response variable across a spatial gradient.
-If we're sampling this at diff points in space, we'd include space as a random efect-want to know variability of the effects of spatial diversity on dataset

## REPEATED MEASUREMENTS AND AUTOCORRELATION

In many situations where monitoring is conducted, samples taken repeatedly at a given site may not be considered truly independent. The conditions present on a given day may be dependent on conditions present earlier in time. This is clearly an issue for the way we might traditionally think of experimental design and statistical independence, but this type of study design is often of interest in the field of environmental science. We can set up models to consider autocorrelation of time within a given place. One example of this type of model is a **repeated measures ANOVA** to account for autocorrelation.
-taking samples repeatdely that aren't independent of one another

Let's think about the situation of temperature monitoring in the NTL-LTER lake sites, Peter and Paul Lakes. We might be interested to know whether surface temperatures in the summer have increased over time in response to climate change. However, we know that (a) temperature conditions on a given date are dependent on conditions earlier in the season, and (b) there is considerable variability across the summer season within a year (i.e., cooler temperatures occurring in June vs. August). We can set up a hierarchical model to deal with the autocorrelation by date as well as the variability associated with seasonality.

Let's wrangle our data and visualize a preliminary relationship between our variables of interest.
```{r}
PeterPaul.summertemp <- 
  PeterPaul.chem %>%
  select(lakename:temperature_C) %>%
  #filter for Julian days in June-August and surface measurements
  filter(daynum > 151 & daynum < 243 & depth == 0 ) %>%
  #add a "week" column to represent seasonality
  mutate(Week = week(sampledate)) %>%
  #code won't work (autocorrelation won't work if there are NAs!!!)
  na.exclude()

ggplot(PeterPaul.summertemp, aes(x = sampledate, y = temperature_C, color = lakename)) +
  geom_point() +
  scale_color_manual(values = c("#7fcdbb", "#253494"))
```

Next, we will determine the degree of temporal autocorrelation in our dataset. We will use the package `nlme` for our analyses. Another good package for running hierarchical, or mixed-effects, models is `lme4`. For the basic types of hierarchical models, these packages have about the same functionality.

Temperatures on a single day are dependent on temperatures earlier in the season
```{r}
# Determine autocorrelation in residuals
TempTest.auto <- lme(data = PeterPaul.summertemp,
                     temperature_C ~ sampledate * lakename, #fixed effects ANCOVA model with an interaction term
                     random = ~1|Week)           #specifying a random effect

#lme-mixed effects function

TempTest.auto
```

#Random effects: 
###We're interested in knowing what the variability is among the weeks
###Gives us STD of temperature associated with the weeks
###1.58=standard deviation of temperature across the season
###863 observations=number of rows in dataset
###Number of groups=14 weeks from June through August

#Quantifies autocorrelation associated with our model
```{r}
ACF(TempTest.auto)
```

Autocorrelation associated with lag 0 is always 1
2nd value=always falls between 0 and 1(0-100%)
-->In this case, it's 0.42-42% of variability associated with time is autocorrelated from previous dates
-->This makes sense: if we have a colder year, temperatures will depend on temps earlier in season and will be colder



This model structure should look familiar, with a typical linear model structure and dataframe defined. The addition here is that we have defined Week as a random variable. Essentially, we are interested not in the specific effects of each week but in the variability among weeks, so we have defined it as a random effect (essentially coming from a larger distribution of seasonal variability). 

The ~1 statement indicates that each week has its own intercept in the model. From here, we want to take the first order correlation to specify our autocorrelation structure. From the ACF output, we take the 2nd value (the innermost group level) to define the degree of autocorrelation. This number will always fall between 0 and 1. Notice that there is a fairly large degree of autocorrelation in our variables.



We will now create a repeated measures ANOVA model now that we have defined our autocorrelation structure. The way we have set up this model, we are considering temporal autocorrelation within the levels of Week, and we have retained Week as a random effect. 

The correlation statement in the model is defined as follows: `correlation = structure(form = ~ time | subjvar)`, where structure is the autocorrelative structure (options in `?corClasses`), time is the temporal variable, and subjvar is the variable for experimental units.

```{r, warning = FALSE}
TempTest.mixed <- lme(data = PeterPaul.summertemp, temperature_C ~ sampledate * lakename, 
                     random = ~1|Week, 
                     correlation = corAR1(form = ~ sampledate/lakename|Week, value = 0.423),method = "REML")


#specify autocorrelation structure of order 1 (from output of ACF test)
#sampledate is duplicated in some cases, so need to split up by lake
#takes sample dates associated with one lake at a time. Put time on left side of function and subject variable on right side of function
                     #If you're doing a spacial random effect, it goes in corAR1 function
                     #define method as restricted maximum likelihood
                     


```


```{r}
summary(TempTest.mixed)
```


###Notice the STD is different than earlier-bc we didn't specify autocorrelation function in previous model
###Fixed effects-->
Our intercept is significantly different from 0- it is 20 degrees celcius, which is the temperature at Paul Lake on the first day of summer
sampledate parameter-->For each day(one unit increase), the lake temperature increases by 0.0001 degree
lakenamePeterLake-->no significance of lakename
interaction term: not a significant effect on date:Lake interaction

###0.0001*365*32=1.168
###The temperature has warmed by a degree
###this may affect biota accustomed to certain temperatures-->this could negatively affect trout


#Run as fixed-effect model only
```{r}
TempTest.fixed <- gls(data = PeterPaul.summertemp,
                      temperature_C ~ sampledate * lakename, 
                      method = "REML")

```


```{r}
summary(TempTest.fixed)
```

### Compare the random effects model with the fixed effects model

###Looks like we have similar coefficients and similar p-values on our new fixed effects model as compared to our random effects model
# The p-value tells us whether those models have a significantly different fit

```{r}
anova(TempTest.mixed, TempTest.fixed)
```

### The lower the AIC, the better, so we have more variability in model structure(error) accounted for by our mixed effects model that includes week as a random effect
###p-value of <0.0001-model fit is significantly different between these two models
###0.000085*365*32=0.9928
###This is less than a degree of temperature change, which could be significant in affecting biota






# Post-hoc test associated with Mixed Effects Models

### This will yield groupings of temperature by lake for the average date value
```{r}

TempTest.posthoc = lsmeans(TempTest.mixed, ~ sampledate * lakename)
cld(TempTest.posthoc, alpha = 0.05, Letters = letters, adjust = "tukey") #gives us a posthot test-places two groups in a
```
###Both lakes are in group a because they not in groups that are statistically significant from each other. Peter and Paul Lakes had statistically the same relationship over time

If you have a small sample size or a small number of groups in your random effect, using a mixed effect model might reduce model's statistical power

# Display our final relationship
```{r}
ggplot(PeterPaul.summertemp, aes(x = sampledate, y = temperature_C, color = lakename)) +
  geom_point() +
  scale_color_manual(values = c("#7fcdbb", "#253494")) +
  geom_abline(intercept = 20.47, slope = 0.0001)+
labs(title="The Effect of Sample Date on Temperature", x="Sample Date",
       y="Temperature (degrees C)")

```


Question: How would you interpret the collective results of your mixed effects model in the context of the study question?

> ANSWER: 
